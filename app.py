import streamlit as st
import os
import sounddevice as sd
import soundfile as sf
import numpy as np
import tempfile
from dotenv import load_dotenv
from elevenlabs.client import ElevenLabs
from google.genai import Client
from google.genai.errors import ClientError
import time

# =============================
# Page Configuration
# =============================
st.set_page_config(
    page_title="à¨ªà©°à¨œà¨¾à¨¬à©€/Ø§Ø±Ø¯Ùˆ AI Voice Bot",
    page_icon="ğŸ¤",
    layout="centered"
)

# =============================
# Load Environment Variables
# =============================
load_dotenv()

GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
ELEVENLABS_API_KEY = os.getenv("ELEVENLABS_API_KEY")

if not GEMINI_API_KEY or not ELEVENLABS_API_KEY:
    st.error("âŒ Missing API keys in .env file")
    st.stop()

# =============================
# Initialize Clients
# =============================
@st.cache_resource
def initialize_clients():
    genai_client = Client(
        api_key=GEMINI_API_KEY,
        http_options={"api_version": "v1"}
    )
    eleven_client = ElevenLabs(api_key=ELEVENLABS_API_KEY)
    return genai_client, eleven_client

genai_client, eleven_client = initialize_clients()

# =============================
# Detect Available Gemini Model
# =============================
@st.cache_data
def get_working_model():
    models = genai_client.models.list()
    for m in models:
        if "flash" in m.name.lower():
            return m.name.replace("models/", "")
    return models[0].name.replace("models/", "")

MODEL_NAME = get_working_model()

# =============================
# Record Audio from Mic
# =============================
def record_audio(duration=5, sample_rate=16000):
    recording = sd.rec(
        int(duration * sample_rate),
        samplerate=sample_rate,
        channels=1,
        dtype="int16",
    )
    sd.wait()
    temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
    sf.write(temp_file.name, recording, sample_rate)
    return temp_file.name

# =============================
# Speech to Text with Multiple Language Attempts
# =============================
def speech_to_text_multilang(audio_path):
    """
    Try transcribing with both Punjabi and Urdu to see which works better.
    Returns: (transcribed_text, detected_language_code)
    """
    results = []
    
    # Try Urdu first
    try:
        with open(audio_path, "rb") as audio_file:
            transcript_ur = eleven_client.speech_to_text.convert(
                file=audio_file,
                model_id="scribe_v1",
                language_code="urd"  # Urdu
            )
            if transcript_ur.text.strip():
                results.append(("urd", transcript_ur.text.strip()))
    except Exception as e:
        pass
    
    # Try Punjabi
    try:
        with open(audio_path, "rb") as audio_file:
            transcript_pa = eleven_client.speech_to_text.convert(
                file=audio_file,
                model_id="scribe_v1",
                language_code="pan"  # Punjabi
            )
            if transcript_pa.text.strip():
                results.append(("pan", transcript_pa.text.strip()))
    except Exception as e:
        pass
    
    # If we have results, let user choose or use AI to detect
    if results:
        # For now, return the first successful result
        # You can enhance this by comparing which one makes more sense
        return results[0][1], results[0][0]
    
    return "", "pan"

# =============================
# Intelligent Language Detection using Gemini
# =============================
def detect_language_with_ai(text):
    """
    Use Gemini to detect if the text is Punjabi or Urdu.
    This is more reliable than script detection.
    """
    if not text.strip():
        return "pan"
    
    detection_prompt = f"""You are a language detection expert. 
Analyze the following text and determine if it is:
1. Punjabi (à¨ªà©°à¨œà¨¾à¨¬à©€) - can be written in Gurmukhi or Shahmukhi script
2. Urdu (Ø§Ø±Ø¯Ùˆ) - written in Perso-Arabic script
3. English

Text: "{text}"

Respond with ONLY ONE WORD: either "punjabi", "urdu", or "english"
Do not provide any explanation, just the language name in lowercase."""

    try:
        response = genai_client.models.generate_content(
            model=MODEL_NAME,
            contents=detection_prompt,
        )
        
        detected = response.text.strip().lower()
        
        if "urdu" in detected:
            return "urd"
        elif "punjabi" in detected or "panjabi" in detected:
            return "pan"
        elif "english" in detected:
            return "eng"
        else:
            # Fallback to script detection
            return fallback_script_detection(text)
            
    except Exception as e:
        st.warning(f"AI detection failed: {e}")
        return fallback_script_detection(text)

# =============================
# Fallback Script Detection
# =============================
def fallback_script_detection(text):
    """Fallback method using character analysis"""
    if not text:
        return "pan"
    
    # Count different script characters
    gurmukhi = sum(1 for c in text if '\u0A00' <= c <= '\u0A7F')
    perso_arabic = sum(1 for c in text if '\u0600' <= c <= '\u06FF' or '\u0750' <= c <= '\u077F')
    latin = sum(1 for c in text if c.isalpha() and ord(c) < 128)
    
    # Urdu-specific characters
    urdu_specific = sum(1 for c in text if c in 'ÚºÛ’Û“ÛÚ¾')
    
    # Punjabi-specific (Shahmukhi)
    punjabi_specific = sum(1 for c in text if c in 'à©œà©')
    
    if gurmukhi > 0:
        return "pan"
    elif urdu_specific > punjabi_specific and perso_arabic > 0:
        return "urd"
    elif latin > perso_arabic and latin > gurmukhi:
        return "eng"
    else:
        # When in doubt, ask user or default
        return "urd" if perso_arabic > 0 else "pan"

# =============================
# Gemini Response with Language Detection
# =============================
def generate_response(prompt, detected_language):
    """
    Generate response in the same language as the user's input.
    """
    if not prompt.strip():
        return ""
    
    # Language-specific instructions
    language_instructions = {
        "urd": """You are a helpful AI assistant. The user is speaking in Urdu (Ø§Ø±Ø¯Ùˆ). 
You MUST respond ONLY in Urdu using Perso-Arabic/Nastaliq script.
Important: This is URDU, not Punjabi. Use proper Urdu vocabulary and grammar.
Keep your responses natural, conversational, and friendly in Urdu.
Do not mix languages. Use only Urdu (Ø§Ø±Ø¯Ùˆ).""",
        
        "pan": """You are a helpful AI assistant. The user is speaking in Punjabi (à¨ªà©°à¨œà¨¾à¨¬à©€). 
You MUST respond ONLY in Punjabi.
Important: This is PUNJABI, not Urdu. Use proper Punjabi vocabulary and grammar.
You can use either Gurmukhi (à¨ªà©°à¨œà¨¾à¨¬à©€) or Shahmukhi (Ù¾Ù†Ø¬Ø§Ø¨ÛŒ) script.
Keep your responses natural, conversational, and friendly in Punjabi.
Do not mix languages. Use only Punjabi.""",
        
        "eng": """You are a helpful AI assistant. The user is speaking in English.
Respond in English with natural and conversational language."""
    }
    
    system_instruction = language_instructions.get(detected_language, language_instructions["pan"])
    
    full_prompt = f"{system_instruction}\n\nUser: {prompt}\n\nAssistant:"
    
    response_text = ""
    try:
        stream = genai_client.models.generate_content_stream(
            model=MODEL_NAME,
            contents=full_prompt,
        )
        for chunk in stream:
            if chunk.text:
                response_text += chunk.text
        return response_text.strip()
    except ClientError as e:
        st.error(f"âŒ Gemini API Error: {e}")
        return ""

# =============================
# Text to Speech
# =============================
def speak_text(text):
    if not text.strip():
        return
    
    try:
        audio_bytes = eleven_client.text_to_speech.convert(
            voice_id="21m00Tcm4TlvDq8ikWAM",
            model_id="eleven_turbo_v2_5",
            text=text,
        )
        
        temp_audio = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
        with open(temp_audio.name, "wb") as f:
            for chunk in audio_bytes:
                f.write(chunk)
        
        data, samplerate = sf.read(temp_audio.name, dtype="float32")
        sd.play(data, samplerate)
        sd.wait()
        
        os.remove(temp_audio.name)
    except Exception as e:
        st.error(f"âŒ TTS Error: {e}")

# =============================
# Get Language Display Name
# =============================
def get_language_display(lang_code):
    """Return display name and flag for language code"""
    lang_map = {
        "urd": ("Urdu (Ø§Ø±Ø¯Ùˆ)", "ğŸ‡µğŸ‡°"),
        "pan": ("Punjabi (à¨ªà©°à¨œà¨¾à¨¬à©€/Ù¾Ù†Ø¬Ø§Ø¨ÛŒ)", "ğŸ‡®ğŸ‡³"),
        "eng": ("English", "ğŸ‡¬ğŸ‡§")
    }
    return lang_map.get(lang_code, ("Unknown", "ğŸŒ"))

# =============================
# Streamlit UI
# =============================
st.title("ğŸ¤ à¨ªà©°à¨œà¨¾à¨¬à©€/Ø§Ø±Ø¯Ùˆ AI Voice Bot")
st.markdown("### ğŸ—£ï¸ Speak in Any Language - AI Detects & Responds")
st.markdown("**Supported:** Punjabi (à¨ªà©°à¨œà¨¾à¨¬à©€/Ù¾Ù†Ø¬Ø§Ø¨ÛŒ) | Urdu (Ø§Ø±Ø¯Ùˆ) | English")
st.markdown("---")

# Initialize session state
if 'conversation_history' not in st.session_state:
    st.session_state.conversation_history = []

# Language selection override (optional manual selection)
st.sidebar.header("âš™ï¸ Settings")
manual_override = st.sidebar.checkbox("ğŸ”§ Manual Language Override", value=False)
if manual_override:
    selected_lang = st.sidebar.selectbox(
        "Select Language",
        options=["urd", "pan", "eng"],
        format_func=lambda x: get_language_display(x)[0]
    )
else:
    selected_lang = None

# Display conversation history
if st.session_state.conversation_history:
    st.subheader("ğŸ’¬ Conversation History")
    for i, entry in enumerate(st.session_state.conversation_history):
        with st.container():
            user_lang_name, user_flag = get_language_display(entry.get('user_language', 'pan'))
            ai_lang_name, ai_flag = get_language_display(entry.get('ai_language', 'pan'))
            
            st.markdown(f"**ğŸ§‘ You {user_flag} ({user_lang_name}):** {entry['user']}")
            st.markdown(f"**ğŸ¤– AI {ai_flag} ({ai_lang_name}):** {entry['ai']}")
            st.markdown("---")

# Center the mic button
col1, col2, col3 = st.columns([1, 2, 1])

with col2:
    if st.button("ğŸ¤ Press to Speak", type="primary", use_container_width=True):
        with st.spinner("ğŸ™ï¸ Recording... (5 seconds)"):
            # Record audio
            audio_path = record_audio(duration=5)
        
        with st.spinner("ğŸ”„ Transcribing with AI language detection..."):
            # Convert speech to text
            user_text, initial_lang = speech_to_text_multilang(audio_path)
            
            if not user_text:
                st.warning("âš ï¸ Ú©ÙˆØ¦ÛŒ Ø¢ÙˆØ§Ø² Ù†ÛÛŒÚº Ù…Ù„ÛŒ / à¨•à©‹à¨ˆ à¨†à¨µà¨¾à¨œà¨¼ à¨¨à¨¹à©€à¨‚ à¨®à¨¿à¨²à©€ / No voice detected")
                os.remove(audio_path)
            else:
                # Use manual override if enabled, otherwise use AI detection
                if manual_override:
                    detected_lang = selected_lang
                    st.info(f"ğŸ”§ Manual override: {get_language_display(detected_lang)[0]}")
                else:
                    with st.spinner("ğŸ¤– Detecting language with AI..."):
                        detected_lang = detect_language_with_ai(user_text)
                
                lang_name, lang_flag = get_language_display(detected_lang)
                
                st.success(f"**ğŸ§‘ You {lang_flag}:** {user_text}")
                st.info(f"âœ… Detected Language: **{lang_name}**")
                
                with st.spinner(f"ğŸ¤– Generating response in {lang_name}..."):
                    # Generate AI response in the detected language
                    response = generate_response(user_text, detected_lang)
                    
                    if response:
                        st.info(f"**ğŸ¤– AI {lang_flag}:** {response}")
                        
                        # Add to conversation history
                        st.session_state.conversation_history.append({
                            'user': user_text,
                            'ai': response,
                            'user_language': detected_lang,
                            'ai_language': detected_lang
                        })
                        
                        with st.spinner(f"ğŸ”Š Speaking..."):
                            speak_text(response)
                        
                        st.success("âœ… Response completed!")
                    else:
                        st.error("âŒ Failed to generate response")
                
                os.remove(audio_path)

# Footer
st.markdown("---")
st.markdown("**â„¹ï¸ Note:** Each recording is 5 seconds long. Press the mic button to start.")
st.markdown("**ğŸ¤– AI Model:** " + MODEL_NAME)
st.markdown("**ğŸ” Detection:** AI-powered language detection")

# Clear conversation button
if st.session_state.conversation_history:
    col1, col2, col3 = st.columns([1, 1, 1])
    with col2:
        if st.button("ğŸ—‘ï¸ Clear Conversation", type="secondary", use_container_width=True):
            st.session_state.conversation_history = []
            st.rerun()